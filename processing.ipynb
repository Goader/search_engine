{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(2021)\n",
    "seed = 2021\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50447"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "\n",
    "DOCS_DIR = 'docs'\n",
    "for dfile in os.listdir(DOCS_DIR):\n",
    "    with open(os.path.join(DOCS_DIR, dfile), 'r', encoding='utf-8') as file:\n",
    "        docs.append(file.read())\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating *bag-of-words*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and execute if the problem occurs below\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# # add another download queries if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from BIT Python (I am one of the teachers there)\n",
    "def create_bag_of_words(text, idxs=dict(), update=False):\n",
    "    text = text.lower()\n",
    "\n",
    "    # partition into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        sentence_words = word_tokenize(sentence)\n",
    "        words.extend(sentence_words)\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # remove punctuation\n",
    "    punctuation = set(string.punctuation)\n",
    "    punctuation.add(\"...\")\n",
    "    words = [word for word in words if word not in punctuation]\n",
    "\n",
    "    # change words to their stems\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # remove too short stems\n",
    "    words = [word for word in words if len(word) >= 3]\n",
    "\n",
    "    if not update:\n",
    "        vec = np.zeros(len(idxs))\n",
    "        for word in words:\n",
    "            idx = idxs.get(word, -1)\n",
    "            if idx >= 0:\n",
    "                vec[idxs[word]] += 1\n",
    "        return vec\n",
    "    else:\n",
    "        for word in words:\n",
    "            if word not in idxs:\n",
    "                idxs[word] = len(idxs)\n",
    "        return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "block_size = 500\n",
    "offset = 0\n",
    "idxs = dict()\n",
    "while offset < len(docs):\n",
    "    create_bag_of_words(' '.join(docs[offset:offset+block_size]), \n",
    "                        idxs=idxs, update=True)\n",
    "    offset += block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860462,\n",
       " {'imagin': 0,\n",
       "  'imag': 1,\n",
       "  'audio': 2,\n",
       "  'file': 3,\n",
       "  'would': 4,\n",
       "  'like': 5,\n",
       "  'transfer': 6,\n",
       "  'friend': 7,\n",
       "  'send': 8,\n",
       "  'raw': 9,\n",
       "  'format': 10,\n",
       "  'data': 11,\n",
       "  'could': 12,\n",
       "  'time-consum': 13,\n",
       "  'potenti': 14,\n",
       "  'ineffici': 15,\n",
       "  'especi': 16,\n",
       "  'size': 17,\n",
       "  'big': 18,\n",
       "  'convert': 19,\n",
       "  'origin': 20,\n",
       "  'bit': 21,\n",
       "  'compress': 22,\n",
       "  'sourc': 23,\n",
       "  'make': 24,\n",
       "  'much': 25,\n",
       "  'faster': 26,\n",
       "  'speed': 27,\n",
       "  'right': 28,\n",
       "  'autoencod': 29,\n",
       "  'save': 30,\n",
       "  'valuabl': 31,\n",
       "  'space': 32,\n",
       "  'instead': 33,\n",
       "  'bottleneck': 34,\n",
       "  'slower': 35,\n",
       "  'uncompress': 36,\n",
       "  'post': 37,\n",
       "  'discuss': 38,\n",
       "  'tensorflow': 39,\n",
       "  'v2.4.befor': 40,\n",
       "  'get': 41,\n",
       "  'technic': 42,\n",
       "  'detail': 43,\n",
       "  'let': 44,\n",
       "  'look': 45,\n",
       "  'interest': 46,\n",
       "  'applic': 47,\n",
       "  'use': 48,\n",
       "  'remov': 49,\n",
       "  'nois': 50,\n",
       "  'denois': 51,\n",
       "  '.clear': 52,\n",
       "  'clarifi': 53,\n",
       "  'imagefil': 54,\n",
       "  'miss': 55,\n",
       "  'piec': 56,\n",
       "  'inpaint': 57,\n",
       "  '.demo': 58,\n",
       "  'fill': 59,\n",
       "  'imagedimension': 60,\n",
       "  'reduct': 61,\n",
       "  'cluster': 62,\n",
       "  'recommend': 63,\n",
       "  'systems.a': 64,\n",
       "  'class': 65,\n",
       "  'known': 66,\n",
       "  'variat': 67,\n",
       "  'even': 68,\n",
       "  'learn': 69,\n",
       "  'generat': 70,\n",
       "  'howev': 71,\n",
       "  'vanilla': 72,\n",
       "  'fail': 73,\n",
       "  'perform': 74,\n",
       "  'accur': 75,\n",
       "  'due': 76,\n",
       "  'shortcom': 77,\n",
       "  'post.autoencod': 78,\n",
       "  'featur': 79,\n",
       "  'extractor': 80,\n",
       "  'downstream': 81,\n",
       "  'task': 82,\n",
       "  'classif': 83,\n",
       "  'detection.autoencod': 84,\n",
       "  'also': 85,\n",
       "  'wide': 86,\n",
       "  'leverag': 87,\n",
       "  'semant': 88,\n",
       "  'segment': 89,\n",
       "  'one': 90,\n",
       "  'work': 91,\n",
       "  'segnet': 92,\n",
       "  'develop': 93,\n",
       "  'multi-class': 94,\n",
       "  'pixel-wis': 95,\n",
       "  'urban': 96,\n",
       "  'road': 97,\n",
       "  'scene': 98,\n",
       "  'dataset': 99,\n",
       "  'publish': 100,\n",
       "  'member': 101,\n",
       "  'comput': 102,\n",
       "  'vision': 103,\n",
       "  'group': 104,\n",
       "  'univers': 105,\n",
       "  'cambridg': 106,\n",
       "  'tri': 107,\n",
       "  'demo': 108,\n",
       "  'convolut': 109,\n",
       "  'encoder-decod': 110,\n",
       "  'architectur': 111,\n",
       "  'demothi': 112,\n",
       "  'articl': 113,\n",
       "  'follow': 114,\n",
       "  'introduct': 115,\n",
       "  'works.discuss': 116,\n",
       "  'object': 117,\n",
       "  'function.impl': 118,\n",
       "  'fashion-mnist': 119,\n",
       "  'dataset.impl': 120,\n",
       "  'googl': 121,\n",
       "  'cartoon': 122,\n",
       "  'dataset.bonusnot': 123,\n",
       "  'theori': 124,\n",
       "  'part': 125,\n",
       "  'test': 126,\n",
       "  'dive': 127,\n",
       "  'deep': 128,\n",
       "  'experiment': 129,\n",
       "  'analyz': 130,\n",
       "  'good': 131,\n",
       "  'understand': 132,\n",
       "  'strength': 133,\n",
       "  'weaknesses.5': 134,\n",
       "  'various': 135,\n",
       "  'experi': 136,\n",
       "  'visual': 137,\n",
       "  'latent-spac': 138,\n",
       "  'sampl': 139,\n",
       "  'uniform': 140,\n",
       "  'normal': 141,\n",
       "  'distribution.6': 142,\n",
       "  'result': 143,\n",
       "  'step': 144,\n",
       "  'point': 145,\n",
       "  'shortcomings.7': 146,\n",
       "  'summari': 147,\n",
       "  'conclusionwhat': 148,\n",
       "  'unsupervis': 149,\n",
       "  'neural': 150,\n",
       "  'network': 151,\n",
       "  'primarili': 152,\n",
       "  'inher': 153,\n",
       "  'ident': 154,\n",
       "  'function': 155,\n",
       "  'first': 156,\n",
       "  'introduc': 157,\n",
       "  '1980s': 158,\n",
       "  'promot': 159,\n",
       "  'paper': 160,\n",
       "  'hinton': 161,\n",
       "  'salakhutdinov': 162,\n",
       "  '2006.': 163,\n",
       "  'aim': 164,\n",
       "  'general': 165,\n",
       "  'latent': 166,\n",
       "  'represent': 167,\n",
       "  'encod': 168,\n",
       "  'help': 169,\n",
       "  'domain': 170,\n",
       "  'process': 171,\n",
       "  'text': 172,\n",
       "  'audio.i': 173,\n",
       "  'partner': 174,\n",
       "  'opencv.org': 175,\n",
       "  'bring': 176,\n",
       "  'offici': 177,\n",
       "  'cours': 178,\n",
       "  'machin': 179,\n",
       "  'sign': 180,\n",
       "  'take': 181,\n",
       "  'skill': 182,\n",
       "  'next': 183,\n",
       "  'level': 184,\n",
       "  'opencv.orgin': 185,\n",
       "  'fed': 186,\n",
       "  'grayscal': 187,\n",
       "  'color': 188,\n",
       "  'input': 189,\n",
       "  'system': 190,\n",
       "  'reconstruct': 191,\n",
       "  'fewer': 192,\n",
       "  'similar': 193,\n",
       "  'spirit': 194,\n",
       "  'dimension': 195,\n",
       "  'algorithm': 196,\n",
       "  'princip': 197,\n",
       "  'compon': 198,\n",
       "  'analysi': 199,\n",
       "  'creat': 200,\n",
       "  'necessari': 201,\n",
       "  'element': 202,\n",
       "  'preserv': 203,\n",
       "  'non-essenti': 204,\n",
       "  'filter': 205,\n",
       "  'layer': 206,\n",
       "  'non-linear': 207,\n",
       "  'consid': 208,\n",
       "  'analysis.th': 209,\n",
       "  'two': 210,\n",
       "  'block': 211,\n",
       "  'number': 212,\n",
       "  'sometim': 213,\n",
       "  'call': 214,\n",
       "  'input.decod': 215,\n",
       "  'representation.2-lay': 216,\n",
       "  'autoencoderth': 217,\n",
       "  'pictur': 218,\n",
       "  'show': 219,\n",
       "  '2-layer': 220,\n",
       "  'hidden': 221,\n",
       "  'note': 222,\n",
       "  'output': 223,\n",
       "  'neuron': 224,\n",
       "  'five': 225,\n",
       "  'actual': 226,\n",
       "  'valu': 227,\n",
       "  'three': 228,\n",
       "  'real': 229,\n",
       "  'middl': 230,\n",
       "  'decod': 231,\n",
       "  'values.in': 232,\n",
       "  'practic': 233,\n",
       "  'far': 234,\n",
       "  'output.object': 235,\n",
       "  'tensorflowth': 236,\n",
       "  'train': 237,\n",
       "  'obtain': 238,\n",
       "  'weight': 239,\n",
       "  'best': 240,\n",
       "  'minim': 241,\n",
       "  'loss': 242,\n",
       "  'pass': 243,\n",
       "  'decoder.consid': 244,\n",
       "  'paramet': 245,\n",
       "  'consist': 246,\n",
       "  'low-dimension': 247,\n",
       "  'code': 248,\n",
       "  '.both': 249,\n",
       "  'tandem': 250,\n",
       "  'expect': 251,\n",
       "  'metric': 252,\n",
       "  'quantifi': 253,\n",
       "  'differ': 254,\n",
       "  'vector': 255,\n",
       "  'common': 256,\n",
       "  'mean': 257,\n",
       "  'squar': 258,\n",
       "  'error': 259,\n",
       "  'mse': 260,\n",
       "  '.the': 261,\n",
       "  'given': 262,\n",
       "  'equat': 263,\n",
       "  'mini-batch': 264,\n",
       "  'across': 265,\n",
       "  'rais': 266,\n",
       "  'power': 267,\n",
       "  'averag': 268,\n",
       "  'full-batch': 269,\n",
       "  'data.ther': 270,\n",
       "  'kind': 271,\n",
       "  'likevanilla': 272,\n",
       "  'autoencoderdenois': 273,\n",
       "  'autoencoderstack': 274,\n",
       "  'spars': 275,\n",
       "  'autoencodercontrast': 276,\n",
       "  'autoencodervari': 277,\n",
       "  'autoencoderlet': 278,\n",
       "  'move': 279,\n",
       "  'onto': 280,\n",
       "  'implement': 281,\n",
       "  'execut': 282,\n",
       "  'tensorflow.autoencod': 283,\n",
       "  'datasetw': 284,\n",
       "  'famous': 285,\n",
       "  'reconstruction.preview': 286,\n",
       "  'setth': 287,\n",
       "  'databas': 288,\n",
       "  '60,000': 289,\n",
       "  'fashion': 290,\n",
       "  'shown': 291,\n",
       "  'right.each': 292,\n",
       "  '28×28': 293,\n",
       "  'associ': 294,\n",
       "  'label': 295,\n",
       "  'categori': 296,\n",
       "  't-shirt': 297,\n",
       "  'trouser': 298,\n",
       "  'sneaker.not': 299,\n",
       "  'carri': 300,\n",
       "  '11gb': 301,\n",
       "  'pascal': 302,\n",
       "  '1080ti': 303,\n",
       "  'gpu': 304,\n",
       "  'download': 305,\n",
       "  'easili': 306,\n",
       "  'along': 307,\n",
       "  'tutori': 308,\n",
       "  'pleas': 309,\n",
       "  'click': 310,\n",
       "  'button': 311,\n",
       "  'free': 312,\n",
       "  'codeimport': 313,\n",
       "  'modul': 314,\n",
       "  'import': 315,\n",
       "  'packag': 316,\n",
       "  'imageio': 317,\n",
       "  'glob': 318,\n",
       "  'time': 319,\n",
       "  'cv2': 320,\n",
       "  'tensorflow.kera': 321,\n",
       "  'ipython': 322,\n",
       "  'display': 323,\n",
       "  'matplotlib.pyplot': 324,\n",
       "  'plt': 325,\n",
       "  'numpi': 326,\n",
       "  'matplotlib': 327,\n",
       "  'inlin': 328,\n",
       "  'kera': 329,\n",
       "  'begin': 330,\n",
       "  'plot': 331,\n",
       "  'line': 332,\n",
       "  '2-10.load': 333,\n",
       "  'preprocess': 334,\n",
       "  'x_train': 335,\n",
       "  'y_train': 336,\n",
       "  'x_test': 337,\n",
       "  'y_test': 338,\n",
       "  'tf.keras.datasets.fashion_mnist.load_data': 339,\n",
       "  'x_train.reshap': 340,\n",
       "  'x_train.shap': 341,\n",
       "  '.astyp': 342,\n",
       "  'float32': 343,\n",
       "  'x_test.astyp': 344,\n",
       "  '255.': 345,\n",
       "  '255': 346,\n",
       "  'batch': 347,\n",
       "  'shuffl': 348,\n",
       "  'train_dataset': 349,\n",
       "  'tf.data.dataset.from_tensor_slic': 350,\n",
       "  '60000': 351,\n",
       "  '.batch': 352,\n",
       "  '128': 353,\n",
       "  'load': 354,\n",
       "  'relat': 355,\n",
       "  'simpl': 356,\n",
       "  'tf_kera': 357,\n",
       "  'off-the-shelf': 358,\n",
       "  'sinc': 359,\n",
       "  'requir': 360,\n",
       "  'solv': 361,\n",
       "  'problem': 362,\n",
       "  'reshap': 363,\n",
       "  'cast': 364,\n",
       "  'uint8': 365,\n",
       "  'format.then': 366,\n",
       "  '17-18': 367,\n",
       "  'final': 368,\n",
       "  'build': 369,\n",
       "  'pipelin': 370,\n",
       "  'essenc': 371,\n",
       "  'slice': 372,\n",
       "  'tensor': 373,\n",
       "  'allow': 374,\n",
       "  'access': 375,\n",
       "  'specifi': 376,\n",
       "  'buffer': 377,\n",
       "  'affect': 378,\n",
       "  'random': 379,\n",
       "  'shuffle.architectur': 380,\n",
       "  'diagram': 381,\n",
       "  'tensorflowdefin': 382,\n",
       "  'networkdef': 383,\n",
       "  'input_encod': 384,\n",
       "  'keras.input': 385,\n",
       "  'shape=input_encod': 386,\n",
       "  \"name='input_lay\": 387,\n",
       "  'layers.conv2d': 388,\n",
       "  'kernel_size=3': 389,\n",
       "  'strides=': 390,\n",
       "  \"padding='sam\": 391,\n",
       "  \"name='conv_1\": 392,\n",
       "  'layers.batchnorm': 393,\n",
       "  \"name='bn_1\": 394,\n",
       "  'layers.leakyrelu': 395,\n",
       "  \"name='lrelu_1\": 396,\n",
       "  \"name='conv_2\": 397,\n",
       "  \"name='bn_2\": 398,\n",
       "  \"name='lrelu_2\": 399,\n",
       "  \"name='conv_3\": 400,\n",
       "  \"name='bn_3\": 401,\n",
       "  \"name='lrelu_3\": 402,\n",
       "  \"name='conv_4\": 403,\n",
       "  \"name='bn_4\": 404,\n",
       "  \"name='lrelu_4\": 405,\n",
       "  'flatten': 406,\n",
       "  'layers.flatten': 407,\n",
       "  'layers.dens': 408,\n",
       "  \"name='dense_1\": 409,\n",
       "  'model': 410,\n",
       "  'tf.keras.model': 411,\n",
       "  'name=': 412,\n",
       "  'return': 413,\n",
       "  'defin': 414,\n",
       "  'none': 415,\n",
       "  '256': 416,\n",
       "  'conv': 417,\n",
       "  'conv2d': 418,\n",
       "  'batchnorm': 419,\n",
       "  'leakyrelu': 420,\n",
       "  'activ': 421,\n",
       "  'factor': 422,\n",
       "  'two.in': 423,\n",
       "  '4096': 424,\n",
       "  'add': 425,\n",
       "  'dens': 426,\n",
       "  '200': 427,\n",
       "  'say': 428,\n",
       "  'repres': 429,\n",
       "  'values.defin': 430,\n",
       "  'input_decod': 431,\n",
       "  'initi': 432,\n",
       "  'shape=input_decod': 433,\n",
       "  '3136': 434,\n",
       "  'tf.reshap': 435,\n",
       "  \"name='reshape_lay\": 436,\n",
       "  'layers.conv2dtranspos': 437,\n",
       "  \"name='conv_transpose_1\": 438,\n",
       "  \"name='conv_transpose_2\": 439,\n",
       "  \"name='conv_transpose_3\": 440,\n",
       "  \"activation='sigmoid\": 441,\n",
       "  \"name='conv_transpose_4\": 442,\n",
       "  'recal': 443,\n",
       "  'last': 444,\n",
       "  'total': 445,\n",
       "  'conv2dtranspos': 446,\n",
       "  'sigmoid': 447,\n",
       "  'rang': 448,\n",
       "  'two.th': 449,\n",
       "  '.optim': 450,\n",
       "  'functionoptim': 451,\n",
       "  'tf.keras.optimizers.adam': 452,\n",
       "  '0.0005': 453,\n",
       "  'def': 454,\n",
       "  'ae_loss': 455,\n",
       "  'y_true': 456,\n",
       "  'y_pred': 457,\n",
       "  'k.mean': 458,\n",
       "  'k.squar': 459,\n",
       "  'axi': 460,\n",
       "  '1,2,3': 461,\n",
       "  'optim': 462,\n",
       "  'adam': 463,\n",
       "  'argument': 464,\n",
       "  'rate': 465,\n",
       "  'i.e.': 466,\n",
       "  'mean-squar': 467,\n",
       "  'image.train': 468,\n",
       "  'notic': 469,\n",
       "  'tf.function': 470,\n",
       "  'annot': 471,\n",
       "  'caus': 472,\n",
       "  'compil': 473,\n",
       "  'train_step': 474,\n",
       "  'tf.gradienttap': 475,\n",
       "  'enc': 476,\n",
       "  'training=tru': 477,\n",
       "  'generated_imag': 478,\n",
       "  'dec': 479,\n",
       "  'gradients_of_enc': 480,\n",
       "  'encoder.gradi': 481,\n",
       "  'enc.trainable_vari': 482,\n",
       "  'gradients_of_dec': 483,\n",
       "  'decoder.gradi': 484,\n",
       "  'dec.trainable_vari': 485,\n",
       "  'optimizer.apply_gradi': 486,\n",
       "  'zip': 487,\n",
       "  'loop': 488,\n",
       "  'separ': 489,\n",
       "  'decoder.next': 490,\n",
       "  '90-91': 491,\n",
       "  'gradient': 492,\n",
       "  'updat': 493,\n",
       "  'loss.def': 494,\n",
       "  'epoch': 495,\n",
       "  'start': 496,\n",
       "  'time.tim': 497,\n",
       "  'image_batch': 498,\n",
       "  'print': 499,\n",
       "  \"sec'.format\": 500,\n",
       "  '-start': 501,\n",
       "  'everi': 502,\n",
       "  'new': 503,\n",
       "  '.reconstruct': 504,\n",
       "  'imageslet': 505,\n",
       "  'well': 506,\n",
       "  'grid.with': 507,\n",
       "  'respect': 508,\n",
       "  'ground': 509,\n",
       "  'truth': 510,\n",
       "  'judg': 511,\n",
       "  'performance.figs': 512,\n",
       "  'enc.predict': 513,\n",
       "  ':25': 514,\n",
       "  'reconst': 515,\n",
       "  'dec.predict': 516,\n",
       "  'fig': 517,\n",
       "  'plt.figur': 518,\n",
       "  'figsize=': 519,\n",
       "  'figsiz': 520,\n",
       "  'fig.add_subplot': 521,\n",
       "  'i+1': 522,\n",
       "  'ax.axi': 523,\n",
       "  'off': 524,\n",
       "  'ax.text': 525,\n",
       "  '0.5': 526,\n",
       "  '-0.15': 527,\n",
       "  'str': 528,\n",
       "  'label_dict': 529,\n",
       "  'fontsize=10': 530,\n",
       "  \"ha='cent\": 531,\n",
       "  'transform=ax.transax': 532,\n",
       "  'ax.imshow': 533,\n",
       "  'cmap': 534,\n",
       "  'gray': 535,\n",
       "  'observ': 536,\n",
       "  'great': 537,\n",
       "  'job': 538,\n",
       "  'valid': 539,\n",
       "  'coupl': 540,\n",
       "  'later': 541,\n",
       "  'feel': 542,\n",
       "  'jump': 543,\n",
       "  'direct': 544,\n",
       "  'section.autoencod': 545,\n",
       "  'set': 546,\n",
       "  'datathi': 547,\n",
       "  'section': 548,\n",
       "  'implementation.datasetcartoon': 549,\n",
       "  'collect': 550,\n",
       "  'avatar': 551,\n",
       "  'rgb': 552,\n",
       "  'has:10': 553,\n",
       "  'artwork': 554,\n",
       "  'categories,4': 555,\n",
       "  'proport': 556,\n",
       "  'come': 557,\n",
       "  '~1013': 558,\n",
       "  'possibl': 559,\n",
       "  'combin': 560,\n",
       "  'fixed-s': 561,\n",
       "  '512': 562,\n",
       "  '10k': 563,\n",
       "  '100k': 564,\n",
       "  'chosen': 565,\n",
       "  'attribut': 566,\n",
       "  'autoencoder.load': 567,\n",
       "  'datatrain_d': 568,\n",
       "  'tf.keras.preprocessing.image_dataset_from_directori': 569,\n",
       "  'cartoonset100k': 570,\n",
       "  'image_size=': 571,\n",
       "  'batch_size=batch_s': 572,\n",
       "  'label_mode=non': 573,\n",
       "  'normalization_lay': 574,\n",
       "  'layers.experimental.preprocessing.resc': 575,\n",
       "  'scale=': 576,\n",
       "  '1./255': 577,\n",
       "  'normalized_d': 578,\n",
       "  'train_ds.map': 579,\n",
       "  'lambda': 580,\n",
       "  'fair': 581,\n",
       "  'image_dataset_from_directori': 582,\n",
       "  'directori': 583,\n",
       "  'case': 584,\n",
       "  'image_s': 585,\n",
       "  'batch_siz': 586,\n",
       "  'label_mod': 587,\n",
       "  'flag': 588,\n",
       "  'none.fin': 589,\n",
       "  '7.autoencod': 590,\n",
       "  'architectureth': 591,\n",
       "  'feed': 592,\n",
       "  'upsampl': 593,\n",
       "  'produc': 594,\n",
       "  'inputdefin': 595,\n",
       "  \"name='conv_5\": 596,\n",
       "  \"name='bn_5\": 597,\n",
       "  \"name='lrelu_5\": 598,\n",
       "  \"name='conv_transpose_5\": 599,\n",
       "  'imagesit': 600,\n",
       "  'images.reconstruct': 601,\n",
       "  'lat_spac': 602,\n",
       "  'latent=': 603,\n",
       "  'els': 604,\n",
       "  'np.concaten': 605,\n",
       "  'reconstruction.shap': 606,\n",
       "  '5000': 607,\n",
       "  'break': 608,\n",
       "  'variabl': 609,\n",
       "  'store': 610,\n",
       "  'iter': 611,\n",
       "  'littl': 612,\n",
       "  'model.w': 613,\n",
       "  'space.figs': 614,\n",
       "  'pred': 615,\n",
       "  'np.array': 616,\n",
       "  'pred.astyp': 617,\n",
       "  'np.uint8': 618,\n",
       "  'finer': 619,\n",
       "  'sharp': 620,\n",
       "  'perceptu': 621,\n",
       "  'compar': 622,\n",
       "  'complex.i': 623,\n",
       "  'opencv.orgvisu': 624,\n",
       "  'tensorflowthi': 625,\n",
       "  'intuit': 626,\n",
       "  'gap': 627,\n",
       "  'prevent': 628,\n",
       "  'nature.lat': 629,\n",
       "  'project': 630,\n",
       "  'fashion-mnistimgs_visu': 631,\n",
       "  'index': 632,\n",
       "  'np.random.choic': 633,\n",
       "  'len': 634,\n",
       "  'imgs_visu': 635,\n",
       "  'embed': 636,\n",
       "  'plt.scatter': 637,\n",
       "  'alpha=0.5': 638,\n",
       "  's=2': 639,\n",
       "  'plt.xlabel': 640,\n",
       "  'dimension-1': 641,\n",
       "  'size=20': 642,\n",
       "  'plt.ylabel': 643,\n",
       "  'dimension-2': 644,\n",
       "  'plt.xtick': 645,\n",
       "  'plt.ytick': 646,\n",
       "  'plt.titl': 647,\n",
       "  'plt.show': 648,\n",
       "  'chose': 649,\n",
       "  'shape': 650,\n",
       "  'axe': 651,\n",
       "  'scatter': 652,\n",
       "  'plot.th': 653,\n",
       "  'appear': 654,\n",
       "  'symmetr': 655,\n",
       "  'around': 656,\n",
       "  'bound': 657,\n",
       "  '-20': 658,\n",
       "  '-15': 659,\n",
       "  'mani': 660,\n",
       "  'lie': 661,\n",
       "  'negat': 662,\n",
       "  'region': 663,\n",
       "  'posit': 664,\n",
       "  'region.w': 665,\n",
       "  'see': 666,\n",
       "  'outlier': 667,\n",
       "  'dimens': 668,\n",
       "  'extremes.our': 669,\n",
       "  'goal': 670,\n",
       "  'choos': 671,\n",
       "  'distribut': 672,\n",
       "  'meet': 673,\n",
       "  'enforc': 674,\n",
       "  'prior': 675,\n",
       "  'continu': 676,\n",
       "  'specif': 677,\n",
       "  'distribution.w': 678,\n",
       "  'seem': 679,\n",
       "  'irregular': 680,\n",
       "  'signific': 681,\n",
       "  'almost': 682,\n",
       "  'imposs': 683,\n",
       "  'know': 684,\n",
       "  'pick': 685,\n",
       "  'realist': 686,\n",
       "  'henc': 687,\n",
       "  'happen': 688,\n",
       "  'might': 689,\n",
       "  'give': 690,\n",
       "  'arbitrari': 691,\n",
       "  'resembl': 692,\n",
       "  'classes.lat': 693,\n",
       "  't-sne': 694,\n",
       "  'setnow': 695,\n",
       "  '200d': 696,\n",
       "  'graph': 697,\n",
       "  'appli': 698,\n",
       "  'dimensionality-reduct': 699,\n",
       "  'techniqu': 700,\n",
       "  't-stochast': 701,\n",
       "  'relev': 702,\n",
       "  'information.tsn': 703,\n",
       "  'tsne': 704,\n",
       "  'n_components=2': 705,\n",
       "  \"init='pca\": 706,\n",
       "  'random_state=0': 707,\n",
       "  'x_tsne': 708,\n",
       "  'tsne.fit_transform': 709,\n",
       "  'gather': 710,\n",
       "  'previous': 711,\n",
       "  'major': 712,\n",
       "  'discontinu': 713,\n",
       "  'unbound': 714,\n",
       "  '-75': 715,\n",
       "  '100': 716,\n",
       "  '-80': 717,\n",
       "  '.we': 718,\n",
       "  'post-process': 719,\n",
       "  'still': 720,\n",
       "  'pattern': 721,\n",
       "  'lot': 722,\n",
       "  'ignor': 723,\n",
       "  'moreov': 724,\n",
       "  'not.reconstruct': 725,\n",
       "  'spacesreconstruct': 726,\n",
       "  'latent-vector': 727,\n",
       "  'uniformlyw': 728,\n",
       "  'lower': 729,\n",
       "  'upper': 730,\n",
       "  'array': 731,\n",
       "  'concaten': 732,\n",
       "  'decoder.fin': 733,\n",
       "  'images.min_x': 734,\n",
       "  'min': 735,\n",
       "  'max_x': 736,\n",
       "  'max': 737,\n",
       "  'min_i': 738,\n",
       "  'max_i': 739,\n",
       "  'np.random.uniform': 740,\n",
       "  'low=min_x': 741,\n",
       "  'high=max_x': 742,\n",
       "  '10,1': 743,\n",
       "  'low=min_i': 744,\n",
       "  'high=max_i': 745,\n",
       "  'axis=1': 746,\n",
       "  'np.round': 747,\n",
       "  'blurri': 748,\n",
       "  'pixel': 749,\n",
       "  'well-form': 750,\n",
       "  'exampl': 751,\n",
       "  'second': 752,\n",
       "  'row': 753,\n",
       "  'third': 754,\n",
       "  'column': 755,\n",
       "  'close': 756,\n",
       "  'trouser.w': 757,\n",
       "  'argu': 758,\n",
       "  'boundari': 759,\n",
       "  'reason': 760,\n",
       "  'poor': 761,\n",
       "  'center': 762,\n",
       "  'continuous.reconstruct': 763,\n",
       "  'uniformlyto': 764,\n",
       "  'simpli': 765,\n",
       "  'need': 766,\n",
       "  'minimum': 767,\n",
       "  'maximum': 768,\n",
       "  'matrix': 769,\n",
       "  'whose': 770,\n",
       "  'scale': 771,\n",
       "  'images.figs': 772,\n",
       "  'min_x': 773,\n",
       "  'lat_space.min': 774,\n",
       "  'axis=0': 775,\n",
       "  'lat_space.max': 776,\n",
       "  '10,200': 777,\n",
       "  'np.ab': 778,\n",
       "  'x.shape': 779,\n",
       "  'noticeable.let': 780,\n",
       "  'distributionher': 781,\n",
       "  'decoder.let': 782,\n",
       "  'find': 783,\n",
       "  'result.x': 784,\n",
       "  'np.random.norm': 785,\n",
       "  'fig.subplots_adjust': 786,\n",
       "  'hspace=0.2': 787,\n",
       "  'wspace=0.2': 788,\n",
       "  'wors': 789,\n",
       "  'rather': 790,\n",
       "  'anyth': 791,\n",
       "  'meaning': 792,\n",
       "  'zero': 793,\n",
       "  'varianc': 794,\n",
       "  'one.conclusionfantast': 795,\n",
       "  'avid': 796,\n",
       "  'reader': 797,\n",
       "  'staunch': 798,\n",
       "  'learner': 799,\n",
       "  'want': 800,\n",
       "  'thank': 801,\n",
       "  'congratul': 802,\n",
       "  'quick': 803,\n",
       "  'summar': 804,\n",
       "  's.we': 805,\n",
       "  'autoencoder.w': 806,\n",
       "  'core': 807,\n",
       "  'idea': 808,\n",
       "  'behind': 809,\n",
       "  'functions.then': 810,\n",
       "  'error.impl': 811,\n",
       "  'set.w': 812,\n",
       "  'latent-space.w': 813,\n",
       "  'nature.bi': 814,\n",
       "  'inner': 815,\n",
       "  'shortcomings.did': 816,\n",
       "  'strategi': 817,\n",
       "  'complet': 818,\n",
       "  'excit': 819,\n",
       "  'improv': 820,\n",
       "  'overcom': 821,\n",
       "  'plan': 822,\n",
       "  'comments.subscrib': 823,\n",
       "  'c++': 824,\n",
       "  'python': 825,\n",
       "  'altern': 826,\n",
       "  'receiv': 827,\n",
       "  'resourc': 828,\n",
       "  'guid': 829,\n",
       "  'newslett': 830,\n",
       "  'share': 831,\n",
       "  'opencv': 832,\n",
       "  'written': 833,\n",
       "  'c++/python': 834,\n",
       "  'news': 835,\n",
       "  'conceptu': 836,\n",
       "  'discrimin': 837,\n",
       "  'clear': 838,\n",
       "  'distinguish': 839,\n",
       "  'type': 840,\n",
       "  'classifi': 841,\n",
       "  'dog': 842,\n",
       "  'cat': 843,\n",
       "  'fall': 844,\n",
       "  'modellingproduc': 845,\n",
       "  'problemth': 846,\n",
       "  'got': 847,\n",
       "  'adopt': 848,\n",
       "  'grew': 849,\n",
       "  'base': 850,\n",
       "  'studi': 851,\n",
       "  'concepts.al': 852,\n",
       "  'offbas': 853,\n",
       "  'familiar': 854,\n",
       "  'foundat': 855,\n",
       "  'advanc': 856,\n",
       "  'topic': 857,\n",
       "  'adversari': 858,\n",
       "  'gan': 859,\n",
       "  'bonus': 860,\n",
       "  'goe': 861,\n",
       "  'underneath': 862,\n",
       "  'hood': 863,\n",
       "  'modelled.t': 864,\n",
       "  'contenta': 865,\n",
       "  'mention': 866,\n",
       "  'know-how': 867,\n",
       "  'thing': 868,\n",
       "  'present': 869,\n",
       "  'promin': 870,\n",
       "  'models.what': 871,\n",
       "  'notabl': 872,\n",
       "  'models.comparison': 873,\n",
       "  'modelling.conclusion.discrimin': 874,\n",
       "  'modellingth': 875,\n",
       "  'four': 876,\n",
       "  'domain.what': 877,\n",
       "  'may': 878,\n",
       "  'alreadi': 879,\n",
       "  'superset': 880,\n",
       "  'limit': 881,\n",
       "  'detect': 882,\n",
       "  'panopt': 883,\n",
       "  'keypoint': 884,\n",
       "  'regress': 885,\n",
       "  'languag': 886,\n",
       "  'modelling.th': 887,\n",
       "  'supervis': 888,\n",
       "  'branch': 889,\n",
       "  'among': 890,\n",
       "  'car': 891,\n",
       "  'traffic': 892,\n",
       "  'light': 893,\n",
       "  'truck': 894,\n",
       "  'correspond': 895,\n",
       "  'discov': 896,\n",
       "  'probabl': 897,\n",
       "  'belong': 898,\n",
       "  '.they': 899,\n",
       "  'decis': 900,\n",
       "  'tiger': 901,\n",
       "  'linear': 902,\n",
       "  'away': 903,\n",
       "  'i.e': 904,\n",
       "  'closest': 905,\n",
       "  'considered.discrimin': 906,\n",
       "  'without': 907,\n",
       "  'provid': 908,\n",
       "  'generated.imag': 909,\n",
       "  'models.i': 910,\n",
       "  'indirect': 911,\n",
       "  'certain': 912,\n",
       "  'easier': 913,\n",
       "  'wheel': 914,\n",
       "  'circular': 915,\n",
       "  'length': 916,\n",
       "  'width': 917,\n",
       "  'vertic': 918,\n",
       "  'ring': 919,\n",
       "  'classes.th': 920,\n",
       "  'probabilisticlogist': 921,\n",
       "  'regressiona': 922,\n",
       "  'y|x': 923,\n",
       "  'non-probabilisticsupport': 924,\n",
       "  'svm': 925,\n",
       "  'map': 926,\n",
       "  'hyperplane.discrimin': 927,\n",
       "  'condit': 928,\n",
       "  '.some': 929,\n",
       "  'support': 930,\n",
       "  'machinelogist': 931,\n",
       "  'regressionk-nearest': 932,\n",
       "  'neighbour': 933,\n",
       "  'knn': 934,\n",
       "  'forestdeep': 935,\n",
       "  'alexnet': 936,\n",
       "  'vggnet': 937,\n",
       "  'resnet': 938,\n",
       "  'features.support': 939,\n",
       "  'machinesupport': 940,\n",
       "  'non-parametr': 941,\n",
       "  'popular': 942,\n",
       "  'engin': 943,\n",
       "  'excel': 944,\n",
       "  'less': 945,\n",
       "  'determinist': 946,\n",
       "  'larg': 947,\n",
       "  'protein': 948,\n",
       "  'gene': 949,\n",
       "  'classification.th': 950,\n",
       "  'learning-bas': 951,\n",
       "  'object-detect': 952,\n",
       "  'cnn': 953,\n",
       "  'r-cnn': 954,\n",
       "  'box': 955,\n",
       "  'author': 956,\n",
       "  'class-specif': 957,\n",
       "  'svms': 958,\n",
       "  'image.imag': 959,\n",
       "  'kernel': 960,\n",
       "  'trick': 961,\n",
       "  'implemented.svm': 962,\n",
       "  'kernel-trick': 963,\n",
       "  'hyperplan': 964,\n",
       "  'margin-linear': 965,\n",
       "  'solut': 966,\n",
       "  'figur': 967,\n",
       "  'margin': 968,\n",
       "  'deriv': 969,\n",
       "  'drawn': 970,\n",
       "  'midpoint.th': 971,\n",
       "  'n-1': 972,\n",
       "  'indic': 973,\n",
       "  '.whi': 974,\n",
       "  'increas': 975,\n",
       "  'chanc': 976,\n",
       "  'enough': 977,\n",
       "  'freedom': 978,\n",
       "  'reduc': 979,\n",
       "  'misclassif': 980,\n",
       "  'hand': 981,\n",
       "  'smaller': 982,\n",
       "  'usual': 983,\n",
       "  'lead': 984,\n",
       "  'overfitting.imag': 985,\n",
       "  'depict': 986,\n",
       "  'select': 987,\n",
       "  'maximis': 988,\n",
       "  'points.when': 989,\n",
       "  'higher-dimension': 990,\n",
       "  'polynomi': 991,\n",
       "  'radial': 992,\n",
       "  'basi': 993,\n",
       "  'nonlinear': 994,\n",
       "  'svm.svm': 995,\n",
       "  'sklearn': 996,\n",
       "  'library.from': 997,\n",
       "  'forestlik': 998,\n",
       "  'forest': 999,\n",
       "  ...})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idxs), idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving ```idxs``` to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/idxs.json', 'w') as json_file:\n",
    "    json.dump(idxs, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading ```idxs``` from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/idxs.json', 'r') as json_file:\n",
    "    idxs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Term-by-document* matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A = sparse.csc_matrix((0, 0), dtype=np.uint32)\n",
    "for i, doc in enumerate(docs):\n",
    "    A = sparse.hstack((A, create_bag_of_words(doc, idxs).reshape(-1, 1)))\n",
    "m, n = A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('data/Araw.npz', A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860462, 50447)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sparse.load_npz('data/Araw.npz')\n",
    "m, n = A.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for numpy\n",
    "# def idf(A):\n",
    "#     return A * np.log(n / np.sum(A > 0, axis=1))[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = idf(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = A / np.linalg.norm(A, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = transformer.fit_transform(A.transpose()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = transformer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.62976714,  3.36343026,  4.75204457, ..., 11.1355512 ,\n",
       "       11.1355512 , 11.1355512 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I have found out, I could have done everything using ```sklearn.feature_extraction.text.TfIdfVectorizer``` :)\n",
    "\n",
    "Still, it wasn't too late to use at least ```TfidfTransformer``` ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data/idfs.npy', idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = np.load('data/idfs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse.save_npz('data/A.npz', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860462, 50447)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sparse.load_npz('data/A.npz')\n",
    "m, n = A.shape\n",
    "m, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/docs.json', 'r') as json_file:\n",
    "    docs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COSINE similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(q, A):\n",
    "    return A.transpose().dot(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query, A, idxs, idfs, k=20):\n",
    "    q = create_bag_of_words(query, idxs=idxs)\n",
    "    # it is not neccessary, because it multiplies all the results by the constant for same\n",
    "    # entry, so the sorted order is not being changed\n",
    "    q = q * idfs\n",
    "    q = q / np.linalg.norm(q)\n",
    "    print(q[q > 0], np.where(q > 0)[0])\n",
    "    \n",
    "    sim = cosine(q, A)\n",
    "\n",
    "    indices = np.argpartition(sim, sim.shape[0] - k)[-k:]\n",
    "    return indices[np.argsort(sim[indices])][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tracking algorithm opencv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58830665 0.68879572 0.42362217] [ 196  832 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  390,   398,   386,   612,   332,    91,   393,   339,   370,\n",
       "         389,   202,   568, 39365, 50191,   395,   404,   334, 24703,\n",
       "         353,   402], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = process_query(query, A, idxs, idfs)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV 3 adoption rate - PyImageSearch\n",
      "OpenCV 3.0 released — and the coming changes to the PyImageSearch blog. - PyImageSearch\n",
      "Checking your OpenCV version using Python - PyImageSearch\n",
      "Algorithm - Wikipedia\n",
      "How to install OpenCV 4 on Ubuntu - PyImageSearch\n",
      "OpenCV Installation on Ubuntu, macOS, Windows and Raspberry Pi | Learn OpenCV\n",
      "Installing OpenCV on your Raspberry Pi Zero - PyImageSearch\n",
      "Install OpenCV 4 on macOS - PyImageSearch\n",
      "Face detection with OpenCV and deep learning - PyImageSearch\n",
      "Install OpenCV 3 and Python 2.7+ on Ubuntu - PyimageSearch\n",
      "OpenCV (C++ vs Python) vs MATLAB for Computer Vision | Learn OpenCV\n",
      "Install OpenCV 4 on Raspberry Pi 4 and Raspbian Buster - PyImageSearch\n",
      "Search algorithm - Wikipedia\n",
      "Algorithm (C++) - Wikipedia\n",
      "How to install OpenCV 3 on Raspbian Jessie - PyImageSearch\n",
      "Install OpenCV 3.0 and Python 2.7+ on OSX - PyImageSearch\n",
      "Ubuntu 18.04: How to install OpenCV - PyImageSearch\n",
      "Exact algorithm - Wikipedia\n",
      "macOS: Install OpenCV 3 and Python 2.7 - PyImageSearch\n",
      "OpenCV Object Tracking - PyImageSearch\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perfect results would be tutorials about tracking algorithms posted on Computer Vision blogs, like PyImageSearch or LearnOpenCV. Instead we get lots of tutorials about OpenCV. That's really interesting. I have done this search before having only these 2 blogs as documents (no Wikipedia). And back then, this query gave much better results. \n",
    "\n",
    "The problem is in the following:\n",
    "\n",
    "* 610 documents have word 'OpenCV'\n",
    "* 1345 documents have word 'algorithm'\n",
    "* 4910 documents have word 'track'\n",
    "\n",
    "So the problem is, that the word 'track' is pretty widely used, often having different meaning. And because 'OpenCV' is a name for a library, it is used in less documents, therefore by applying IDF, we get much more weight for 'OpenCV', than for 'tracking'. That's a very good example to see the influence of IDF. Using it without noise reduction via SVD, we can get a problem like this. Still, it performs quite well, taking into considerations, that we've got lots of results about Computer Vision, and even one of the desired articles 'OpenCV Object Tracking'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'object tracking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68388409 0.72959068] [ 117 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  408, 13342, 43276,   403, 18172,   413, 13332, 36675,  6618,\n",
       "         406,   405,   444,  5734, 11137,   175,   402, 39317,   409,\n",
       "        2516, 22429], dtype=int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = process_query(query, A, idxs, idfs)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object tracking with dlib - PyImageSearch\n",
      "Object slicing - Wikipedia\n",
      "Bing's Hollywood - Wikipedia\n",
      "Tracking multiple objects with OpenCV - PyImageSearch\n",
      "BBC Sessions (The Who album) - Wikipedia\n",
      "OpenCV People Counter - PyImageSearch\n",
      "Cloning (programming) - Wikipedia\n",
      "Objection (argument) - Wikipedia\n",
      "Cost object - Wikipedia\n",
      "OpenCV Track Object Movement - PyImageSearch\n",
      "Simple object tracking with OpenCV - PyImageSearch\n",
      "A gentle guide to deep learning object detection - PyImageSearch\n",
      "Journalistic objectivity - Wikipedia\n",
      "Object (grammar) - Wikipedia\n",
      "Object Tracking using OpenCV (C++/Python)\n",
      "OpenCV Object Tracking - PyImageSearch\n",
      "Issue tracking system - Wikipedia\n",
      "Multi-object tracking with dlib - PyImageSearch\n",
      "Track (rail transport) - Wikipedia\n",
      "NCAA Division I Men's Indoor Track and Field Championships - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low rank approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explained_variance(Sig):\n",
    "#     return np.square(Sig) / np.sum(np.square(Sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowrank(A, k=None, exp_var=0.4):\n",
    "#     U, D, V = np.linalg.svd(A)\n",
    "#     if k is None:\n",
    "#         k = np.searchsorted(np.cumsum(explained_variance(D)), exp_var)\n",
    "#     return (U[:, :k] * D[:k]) @ V[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowrank(A, k=250):\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    return svd.fit_transform(A), svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Counter',\n",
       " 'In',\n",
       " 'Out',\n",
       " 'SnowballStemmer',\n",
       " 'TfidfTransformer',\n",
       " 'TruncatedSVD',\n",
       " 'docs',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'i',\n",
       " 'idfs',\n",
       " 'idxs',\n",
       " 'indices',\n",
       " 'indicessvd',\n",
       " 'json_file',\n",
       " 'm',\n",
       " 'n',\n",
       " 'query',\n",
       " 'quit',\n",
       " 'seed',\n",
       " 'stopwords',\n",
       " 'transformer']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you need a lot of memory, so there is a chance you need to delete some variables\n",
    "# filtering out outputs, functions and modules\n",
    "list(filter(lambda x: not x.startswith('_') \n",
    "            and type(eval(x)) != type(cosine)\n",
    "            and type(eval(x)) != type(plt), dir()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Alow, svd_components = lowrank(A.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50447, 250), (250, 860462))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alow.shape, svd_components.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Alow.npy', Alow)\n",
    "np.save('data/Alowcomp.npy', svd_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Alow150, svd_components150 = lowrank(A.transpose(), k=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50447, 150), (150, 860462))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alow150.shape, svd_components150.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Alow150.npy', Alow150)\n",
    "np.save('data/Alowcomp150.npy', svd_components150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Alow50, svd_components50 = lowrank(A.transpose(), k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50447, 50), (50, 860462))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alow50.shape, svd_components50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Alow50.npy', Alow50)\n",
    "np.save('data/Alowcomp50.npy', svd_components50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading low ranked matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alow = np.load('data/Alow.npy')\n",
    "# svd_components = np.load('data/Alowcomp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alow150 = np.load('data/Alow150.npy')\n",
    "# svd_components150 = np.load('data/Alowcomp150.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alow50 = np.load('data/Alow50.npy')\n",
    "# svd_components50 = np.load('data/Alowcomp50.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_svd(query, A, svd_comp, idxs, k=20):\n",
    "    q = create_bag_of_words(query, idxs=idxs)\n",
    "    # it is not neccessary, because it multiplies all the results by the constant for same\n",
    "    # entry, so the sorted order is not being changed\n",
    "    q = q * idfs\n",
    "    q = q / np.linalg.norm(q)\n",
    "    print(q[q > 0], np.where(q > 0)[0])\n",
    "    \n",
    "    sim = A.dot(svd_comp.dot(q))\n",
    "\n",
    "    indices = np.argpartition(sim, sim.shape[0] - k)[-k:]\n",
    "    return indices[np.argsort(sim[indices])][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tracking algorithm opencv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68388409 0.72959068] [ 117 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  408,   409,   355,   413,   350,   444,   403,   406,   402,\n",
       "         367,  8686, 32618, 16640,   412,   309,   232,   369,   175,\n",
       "         371, 38032], dtype=int64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow, svd_components, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object tracking with dlib - PyImageSearch\n",
      "Multi-object tracking with dlib - PyImageSearch\n",
      "Real-time object detection with deep learning and OpenCV - PyImageSearch\n",
      "OpenCV People Counter - PyImageSearch\n",
      "Raspberry Pi: Deep learning object detection with OpenCV - PyImageSearch\n",
      "A gentle guide to deep learning object detection - PyImageSearch\n",
      "Tracking multiple objects with OpenCV - PyImageSearch\n",
      "OpenCV Track Object Movement - PyImageSearch\n",
      "OpenCV Object Tracking - PyImageSearch\n",
      "Faster video file FPS with cv2.VideoCapture and OpenCV - PyImageSearch\n",
      "Album - Wikipedia\n",
      "Album - Wikipedia\n",
      "Framing (social sciences) - Wikipedia\n",
      "Ball Tracking with OpenCV - PyImageSearch\n",
      "OpenCV 'dnn' with NVIDIA GPUs: 1549% faster YOLO, SSD, and Mask R-CNN - PyImageSearch\n",
      "OpenCV Social Distancing Detector - PyImageSearch\n",
      "Human Activity Recognition with OpenCV and Deep Learning - PyImageSearch\n",
      "Object Tracking using OpenCV (C++/Python)\n",
      "Saving key event video clips with OpenCV - PyImageSearch\n",
      "Double album - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'object tracking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68388409 0.72959068] [ 117 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  408,   409,   355,   413,   350,   444,   403,   406,   402,\n",
       "         367,  8686, 32618, 16640,   412,   309,   232,   369,   175,\n",
       "         371, 38032], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow, svd_components, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object tracking with dlib - PyImageSearch\n",
      "Multi-object tracking with dlib - PyImageSearch\n",
      "Real-time object detection with deep learning and OpenCV - PyImageSearch\n",
      "OpenCV People Counter - PyImageSearch\n",
      "Raspberry Pi: Deep learning object detection with OpenCV - PyImageSearch\n",
      "A gentle guide to deep learning object detection - PyImageSearch\n",
      "Tracking multiple objects with OpenCV - PyImageSearch\n",
      "OpenCV Track Object Movement - PyImageSearch\n",
      "OpenCV Object Tracking - PyImageSearch\n",
      "Faster video file FPS with cv2.VideoCapture and OpenCV - PyImageSearch\n",
      "Album - Wikipedia\n",
      "Album - Wikipedia\n",
      "Framing (social sciences) - Wikipedia\n",
      "Ball Tracking with OpenCV - PyImageSearch\n",
      "OpenCV 'dnn' with NVIDIA GPUs: 1549% faster YOLO, SSD, and Mask R-CNN - PyImageSearch\n",
      "OpenCV Social Distancing Detector - PyImageSearch\n",
      "Human Activity Recognition with OpenCV and Deep Learning - PyImageSearch\n",
      "Object Tracking using OpenCV (C++/Python)\n",
      "Saving key event video clips with OpenCV - PyImageSearch\n",
      "Double album - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tracking algorithm opencv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58830665 0.68879572 0.42362217] [ 196  832 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([332, 393, 395, 339, 392, 357, 389, 383, 351, 358, 334, 388, 338,\n",
       "       390, 353, 356, 568, 404, 582, 360], dtype=int64)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow150, svd_components150, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to install OpenCV 4 on Ubuntu - PyImageSearch\n",
      "Installing OpenCV on your Raspberry Pi Zero - PyImageSearch\n",
      "How to install OpenCV 3 on Raspbian Jessie - PyImageSearch\n",
      "Install OpenCV 4 on macOS - PyImageSearch\n",
      "Installing OpenCV 3.0 for both Python 2.7 and Python 3+ on your Raspberry Pi 2 - PyImageSearch\n",
      "Ubuntu 16.04: How to install OpenCV - PyImageSearch\n",
      "Install OpenCV 3 and Python 2.7+ on Ubuntu - PyimageSearch\n",
      "Install guide: Raspberry Pi 3 + Raspbian Jessie + OpenCV 3 - PyImageSearch\n",
      "Optimizing OpenCV on the Raspberry Pi - PyImageSearch\n",
      "Raspbian Stretch: Install OpenCV 3 + Python on your Raspberry Pi - PyImageSearch\n",
      "Ubuntu 18.04: How to install OpenCV - PyImageSearch\n",
      "Install OpenCV 3.0 and Python 3 on Ubuntu - PyImageSearch\n",
      "Install OpenCV 4 on your Raspberry Pi - PyImageSearch\n",
      "OpenCV 3 adoption rate - PyImageSearch\n",
      "macOS: Install OpenCV 3 and Python 2.7 - PyImageSearch\n",
      "macOS: Install OpenCV 3 and Python 3.5 - PyImageSearch\n",
      "Install OpenCV 4 on Raspberry Pi 4 and Raspbian Buster - PyImageSearch\n",
      "Install OpenCV 3.0 and Python 2.7+ on OSX - PyImageSearch\n",
      "Install OpenCV and Python on your Raspberry Pi 2 and B+ - PyImageSearch\n",
      "Install OpenCV 3 on macOS with Homebrew (the easy way) - PyImageSearch\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'object tracking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68388409 0.72959068] [ 117 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  408,   409,   355,   350,   413,   444,   406,  8686, 32618,\n",
       "         367,   412, 16640,   371,   403, 38032,   369,   581,   290,\n",
       "         232,   402], dtype=int64)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow150, svd_components150, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object tracking with dlib - PyImageSearch\n",
      "Multi-object tracking with dlib - PyImageSearch\n",
      "Real-time object detection with deep learning and OpenCV - PyImageSearch\n",
      "Raspberry Pi: Deep learning object detection with OpenCV - PyImageSearch\n",
      "OpenCV People Counter - PyImageSearch\n",
      "A gentle guide to deep learning object detection - PyImageSearch\n",
      "OpenCV Track Object Movement - PyImageSearch\n",
      "Album - Wikipedia\n",
      "Album - Wikipedia\n",
      "Faster video file FPS with cv2.VideoCapture and OpenCV - PyImageSearch\n",
      "Ball Tracking with OpenCV - PyImageSearch\n",
      "Framing (social sciences) - Wikipedia\n",
      "Saving key event video clips with OpenCV - PyImageSearch\n",
      "Tracking multiple objects with OpenCV - PyImageSearch\n",
      "Double album - Wikipedia\n",
      "Human Activity Recognition with OpenCV and Deep Learning - PyImageSearch\n",
      "Multiple cameras with the Raspberry Pi and OpenCV - PyImageSearch\n",
      "Real-time facial landmark detection with OpenCV, Python, and dlib - PyImageSearch\n",
      "OpenCV Social Distancing Detector - PyImageSearch\n",
      "OpenCV Object Tracking - PyImageSearch\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'tracking algorithm opencv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58830665 0.68879572 0.42362217] [ 196  832 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([332, 393, 395, 339, 357, 392, 383, 351, 389, 334, 338, 358, 388,\n",
       "       353, 356, 404, 568, 390, 360, 582], dtype=int64)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow50, svd_components50, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to install OpenCV 4 on Ubuntu - PyImageSearch\n",
      "Installing OpenCV on your Raspberry Pi Zero - PyImageSearch\n",
      "How to install OpenCV 3 on Raspbian Jessie - PyImageSearch\n",
      "Install OpenCV 4 on macOS - PyImageSearch\n",
      "Ubuntu 16.04: How to install OpenCV - PyImageSearch\n",
      "Installing OpenCV 3.0 for both Python 2.7 and Python 3+ on your Raspberry Pi 2 - PyImageSearch\n",
      "Install guide: Raspberry Pi 3 + Raspbian Jessie + OpenCV 3 - PyImageSearch\n",
      "Optimizing OpenCV on the Raspberry Pi - PyImageSearch\n",
      "Install OpenCV 3 and Python 2.7+ on Ubuntu - PyimageSearch\n",
      "Ubuntu 18.04: How to install OpenCV - PyImageSearch\n",
      "Install OpenCV 4 on your Raspberry Pi - PyImageSearch\n",
      "Raspbian Stretch: Install OpenCV 3 + Python on your Raspberry Pi - PyImageSearch\n",
      "Install OpenCV 3.0 and Python 3 on Ubuntu - PyImageSearch\n",
      "macOS: Install OpenCV 3 and Python 2.7 - PyImageSearch\n",
      "macOS: Install OpenCV 3 and Python 3.5 - PyImageSearch\n",
      "Install OpenCV 3.0 and Python 2.7+ on OSX - PyImageSearch\n",
      "Install OpenCV 4 on Raspberry Pi 4 and Raspbian Buster - PyImageSearch\n",
      "OpenCV 3 adoption rate - PyImageSearch\n",
      "Install OpenCV 3 on macOS with Homebrew (the easy way) - PyImageSearch\n",
      "Install OpenCV and Python on your Raspberry Pi 2 and B+ - PyImageSearch\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'object tracking'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68388409 0.72959068] [ 117 3997]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([32618,  8686,  1044, 38032, 19401, 18031, 48987,  6179, 15740,\n",
       "       35158, 24427, 33267, 48955, 25022, 26577, 22918, 20511, 27159,\n",
       "       27242, 15364], dtype=int64)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicessvd = process_query_svd(query, Alow50, svd_components50, idxs)\n",
    "indicessvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album - Wikipedia\n",
      "Album - Wikipedia\n",
      "UK Albums Chart - Wikipedia\n",
      "Double album - Wikipedia\n",
      "Example (musician) - Wikipedia\n",
      "Maurice White - Wikipedia\n",
      "Kill the Lights (Luke Bryan album) - Wikipedia\n",
      "Arctic Monkeys - Wikipedia\n",
      "Feeder (band) - Wikipedia\n",
      "Train station - Wikipedia\n",
      "Train station - Wikipedia\n",
      "When Disaster Strikes... - Wikipedia\n",
      "Sigh No More (Mumford & Sons album) - Wikipedia\n",
      "Older (album) - Wikipedia\n",
      "The Bodyguard (soundtrack) - Wikipedia\n",
      "The Suburbs - Wikipedia\n",
      "Elephant (album) - Wikipedia\n",
      "Colt Ford - Wikipedia\n",
      "Parachutes (Coldplay album) - Wikipedia\n",
      "Savage Garden (Savage Garden album) - Wikipedia\n"
     ]
    }
   ],
   "source": [
    "for i in indicessvd:\n",
    "    print(docs[i]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the RAM restrictions couldn't test big $k$ values for SVD low rank approximation.\n",
    "\n",
    "Firstly, we can see, that writing a proper query is absolutely essential for any possible configuration. We can see that results for 'tracking algorithm opencv' rarely gives us good results. Mostly it gives us results about OpenCV library, and here we can see the influence of IDF. The comment about it is above. So let's take a look at results for the 'object tracking' query.\n",
    "\n",
    "We can see, that results for matrix without low rank approximation contain a lot of wikipedia pages, which have no relation to object tracking, but instead those articles contain lots of 'object' and 'track' words. For example, 'Object slicing - Wikipedia' or 'Object (grammar) - Wikipedia'.\n",
    "\n",
    "For low rank matrix, we do not get such useless results. Most results have some relation to the object tracking. The problem appears when the value of $k$ gets lower. For instance, the results for $k = 250$ are much more specific, than for $k = 150$. $k = 50$ does not have any sense at all. We get utterly useless results having very little relation to the query.\n",
    "\n",
    "So, in my opinion, results for $k > 200$ are the best. I have tested some higher values before, and most of them have given pretty satisfying results. I haven't had an opportunity to test big $k$ values, so it is difficult to tell the upper limit of $k$. (I have over 800,000 dimensions, so it takes a lot of memory). So, subjectively, the values between 200 and 500 are the best. But it may strongly depend on the documents we have. Because, if there are too many different clusters of them based on topics, then we need a bigger $k$ to distinguish them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitb3e3fd3444124dbaadd29881f37793d7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
